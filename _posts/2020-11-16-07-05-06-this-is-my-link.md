
&emsp;linux内核中子系统有各种配置参数，比如内核管理中内存回收的水位信息，cpu调度中的各种调度器的配置信息，文件回写中dirty page的配置等。systcl就是提供运行时配置参数的一个接口，用户通过sysctl命令可以设置这些参数，而无需修改内核。具体的配置参数可以查看内核文档Documentation/sysctl/下的各文件。


&emsp;比如设置内存子系统的dropcaches参数，可使用systcl -w
vm.drop_caches=1来设置。使用strace追踪sysctl命令的系统调用可发现该命令最终是写/proc/sys/drop_caches这个文件。


```
wu@ubuntu:~$ sudo strace sysctl -w vm.drop_caches=1
execve("/sbin/sysctl", ["sysctl", "-w", "vm.drop_caches=1"], [/* 16 vars */]) = 0
brk(NULL)                               = 0x2016000
… …
stat("/proc/sys/vm/drop_caches", {st_mode=S_IFREG|0200, st_size=0, ...}) = 0
open("/proc/sys/vm/drop_caches", O_WRONLY|O_CREAT|O_TRUNC, 0666) = 3
fstat(3, {st_mode=S_IFREG|0200, st_size=0, ...}) = 0
write(3, "1\n", 2)                      = 2
close(3)                                = 0
fstat(1, {st_mode=S_IFCHR|0620, st_rdev=makedev(136, 1), ...}) = 0
write(1, "vm.drop_caches = 1\n", 19vm.drop_caches = 1
)    = 19
close(1)                                = 0
close(2)                                = 0
exit_group(0)                           = ?
+++ exited with 0 +++

```


&emsp;由此就可知，systcl接口就是设置过/proc/sys/目录下的各文件，该目录下包含以下子目录：

```
wu@ubuntu:/proc/sys$ tree -L 1
.
├── abi                      
├── debug
├── dev                #设备相关信息
├── fs                 #特定的文件系统，比如fd，inode，dentry，quota tuning
├── kernel             #tuning全局参数，比如cpu调度，printk，softirq，hung_task，numa，watchdog等
├── net                #网络子系统相关参数，比如ipv4，ipv6，icmp，igmp等
└── vm                 #tuning内存管理相关参数，buffer和cache的管理
```

&emsp;那么在内核中各子系统是如何导出这些参数到procfs，并用户通过echo/cat这些节点来设置参数的呢？


&emsp;在kernel/sysctl.c中定义了某个子系统下的某个参数的相关ctl_table,比如vm.dropcaches，先设置vm目录的参数，访问权限为555，并设置child属性为vm_table。Vm_table结构体数组包含了vm子系统的参数，比如dropcaches参数，设置了该节点的访问权限为644；data属性值为sysctl_drop_caches，该变量在fs/drop_caches.c中定义；该节点的读写处理函数drop_caches_sysctl_hander，在fs/drop_caches.c中实现，通过dointvec_minmax来读出数据 。最后填充好ctl_table结构体后在sysctl_init入口函数注册这些结构体数组。


```
/* The default sysctl tables: */
static struct ctl_table sysctl_base_table[] = {
    {
        .procname   = "kernel",            //   /proc/sys/kernel
        .mode       = 0555,
        .child      = kern_table,
    },
    {
        .procname   = "vm",                //  /proc/sys/vm     
        .mode       = 0555,
        .child      = vm_table,
    },
    {
        .procname   = "fs",               //   /proc/sys/fs
        .mode       = 0555,
        .child      = fs_table,
    },
    {
        .procname   = "debug",            //    /proc/sys/debug
        .mode       = 0555,
        .child      = debug_table,
    },
    {
        .procname   = "dev",             //     /proc/sys/dev
        .mode       = 0555,
        .child      = dev_table,
    },
    { }
};
static struct ctl_table vm_table[] = {
	{
		... ...
	},

    {
        .procname   = "drop_caches",
        .data       = &sysctl_drop_caches,
        .maxlen     = sizeof(int),  // vm.drop_caches 变量4各字节  
        .mode       = 0644,         //    /proc/sys/vm/drop_caches访问权限"644"
        .proc_handler   = drop_caches_sysctl_handler, //        handler
        .extra1     = &one,
        .extra2     = &four,
    },
	{
	
	}
	...
};
int __init sysctl_init(void)
{
    struct ctl_table_header *hdr;
           //注册ctl_table
    hdr = register_sysctl_table(sysctl_base_table);
    kmemleak_not_leak(hdr);
    return 0;
}
int drop_caches_sysctl_handler(struct ctl_table *table, int write,
    void __user *buffer, size_t *length, loff_t *ppos)
{
    int ret;

    ret = proc_dointvec_minmax(table, write, buffer, length, ppos);
    if (ret)
        return ret;
    if (write) {               //如果是写数据
        static int stfu;

        if (sysctl_drop_caches & 1) { //如果drop_caches=1 则清pagecache
            iterate_supers(drop_pagecache_sb, NULL);
            count_vm_event(DROP_PAGECACHE);
        }
        if (sysctl_drop_caches & 2) {//如果drop_caches=2 则清pagecache和slab
            drop_slab();
            count_vm_event(DROP_SLAB);
        }
        if (!stfu) {
            pr_info("%s (%d): drop_caches: %d\n",
                current->comm, task_pid_nr(current),
                sysctl_drop_caches);
        }
        stfu |= sysctl_drop_caches & 4;
    }
    return 0;
}

```

&emsp;通过上述分析，大致梳理了sysctl接口在kernel中运行的大致流程，我们可以在/proc/sys这个根目录下写一个my_sysctl的节点，首先定义并填充ctl_table结构体，并通过register_sysctl_table注册到系统。

```
#include <linux/kernel.h>
#include <linux/mutex.h>
#include <linux/sysctl.h>
static int data;
static struct ctl_table_header * my_ctl_header;
int my_sysctl_callback(struct ctl_table *table, int write,void __user *buffer, size_t *lenp, loff_t *ppos)
 {
        int rc=proc_dointvec(table, write, buffer, lenp, ppos);
        if(write)
        {
            printk("write operation,cur data=%d\n",*((unsigned int*)table->data));
        }

}
/* The default sysctl tables: */
static struct ctl_table my_sysctl_table[] = {
 {
     .procname   = "my_sysctl",
     .mode       = 0644,
     .data      = &data,
     .maxlen         = sizeof(unsigned int),
     .proc_handler   = my_sysctl_callback,
  },
  {

  },
};

static int __init sysctl_test_init(void)
{
    printk("sysctl test init...\n");
     my_ctl_header=register_sysctl_table(my_sysctl_table);

    return 0;
}

static void __exit sysctl_test_exit(void)
{
    printk("sysctl test exit...\n");
    unregister_sysctl_table(my_ctl_header);
}


```


&emsp;通过qemu进入目标文件系统，使用insmod注册驱动，在/proc/sys
目录下出现my_sysctl节点，此时就可以通过cat/echo命令向该节点读写数据，也可以直接通过systcl设置该参数。


```
/mnt # insmod sysctl_test.ko
[   89.904485] sysctl test init...
/mnt # sysctl ^C
/mnt # insmod sysctl_test.ko ^C
/mnt # sysctl my_sysctl
my_sysctl = 0
/mnt # sysctl -w  my_sysctl=2
[  151.278213] write operation,cur data=2
/mnt # sysctl my_sysctl
my_sysctl = 2
/mnt # cat /proc/sys/my_sysctl
2
```
